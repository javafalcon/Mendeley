Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Singh2019,
author = {Singh, Jaswinder and Hanson, Jack and Paliwal, Kuldip and Zhou, Yaoqi},
doi = {10.1038/s41467-019-13395-9},
file = {:E$\backslash$:/360yunpan/Mendeley/RNA secondary structure prediction using an densemble of two-dimensional dep neural networks and transfer learning.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
number = {5047},
publisher = {Springer US},
title = {{RNA secondary structure prediction using an ensemble of two-dimensional deep neural networks and transfer learning}},
url = {http://dx.doi.org/10.1038/s41467-019-13395-9},
volume = {10},
year = {2019}
}
@book{Wang2017e,
abstract = {Recently exciting progress has been made on protein contact prediction, but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction. This paper presents a new deep learning method that predicts contacts by integrating both evolutionary coupling (EC) and sequence conservation information through an ultra-deep neural network formed by two deep residual networks. This deep neural network allows us to model very complex sequence-contact relationship as well as long-range inter-contact correlation. Our method greatly outperforms existing contact prediction methods and leads to much more accurate contact-assisted protein folding. Tested on three datasets of 579 proteins, the average top L long-range prediction accuracy obtained our method, the representative EC method CCMpred and the CASP11 winner MetaPSICOV is 0.47, 0.21 and 0.30, respectively; the average top L/10 long-range accuracy of our method, CCMpred and MetaPSICOV is 0.77, 0.47 and 0.59, respectively. Ab initio folding using our predicted contacts as restraints can yield correct folds (i.e., TMscore{\textgreater}0.6) for 203 test proteins, while that using MetaPSICOV- and CCMpred-predicted contacts can do so for only 79 and 62 proteins, respectively. Further, our contact-assisted models have much better quality than template-based models. Using our predicted contacts as restraints, we can (ab initio) fold 208 of the 398 membrane proteins with TMscore{\textgreater}0.5. By contrast, when the training proteins of our method are used as templates, homology modeling can only do so for 10 of them. One interesting finding is that even if we do not train our prediction models with any membrane proteins, our method works very well on membrane protein prediction. Finally, in recent blind CAMEO benchmark our method successfully folded 5 test proteins with a novel fold.},
author = {Wang, Sheng and Sun, Siqi and Li, Zhen and Zhang, Renyu and Xu, Jinbo},
booktitle = {PLoS Computational Biology},
doi = {10.1371/journal.pcbi.1005324},
file = {:E$\backslash$:/360yunpan/Mendeley/Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model.pdf:pdf},
isbn = {1111111111},
issn = {15537358},
number = {1},
pages = {1--34},
title = {{Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model}},
volume = {13},
year = {2017}
}
@article{Quang2015,
author = {Quang, Daniel and Xie, Xiaohui},
file = {:E$\backslash$:/360yunpan/Mendeley/DanQ a hybrid convolutional and recurrent deep neural network forquantifying the function of DNA sequences.pdf:pdf},
title = {{DanQ : a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences}},
year = {2015}
}
@article{Busia2019,
abstract = {Motivation: Inferring properties of biological sequences--such as determining the species-of-origin of a DNA sequence or the function of an amino-acid sequence--is a core task in many bioinformatics applications. These tasks are often solved using string-matching to map query sequences to labeled database sequences or via Hidden Markov Model-like pattern matching. In the current work we describe and assess an deep learning approach which trains a deep neural network (DNN) to predict database-derived labels directly from query sequences. Results: We demonstrate this DNN performs at state-of-the-art or above levels on a difficult, practically important problem: predicting species-of-origin from short reads of 16S ribosomal DNA. When trained on 16S sequences of over 13,000 distinct species, our DNN achieves read-level species classification accuracy within 2.0{\%} of perfect memorization of training data, and produces more accurate genus-level assignments for reads from held-out species than k-mer, alignment, and taxonomic binning baselines. Moreover, our models exhibit greater robustness than these existing approaches to increasing noise in the query sequences. Finally, we show that these DNNs perform well on experimental 16S mock community dataset. Overall, our results constitute a first step towards our long-term goal of developing a general-purpose deep learning approach to predicting meaningful labels from short biological sequences. Availability: TensorFlow training code is available through GitHub (https://github.com/tensorflow/models/tree/master/research). Data in TensorFlow TFRecord format is available on Google Cloud Storage (gs://brain-genomics-public/research/seq2species/). Contact: seq2species-interest@google.com. Supplementary information: Supplementary data are available in a separate document.},
author = {Busia, Akosua and Dahl, George E and Fannjiang, Clara and Alexander, David H and Dorfman, Elizabeth and Poplin, Ryan and McLean, Cory Y and Chang, Pi-Chuan and DePristo, Mark},
doi = {10.1101/353474},
file = {:E$\backslash$:/360yunpan/Mendeley/A deep learning approach to predict the impact of non-coding sequence variants on 3D chromatin.pdf:pdf},
journal = {bioRxiv},
month = {jan},
pages = {353474},
title = {{A deep learning approach to pattern recognition for short DNA sequences}},
url = {http://biorxiv.org/content/early/2019/01/28/353474.abstract},
year = {2019}
}
@article{Pan2018a,
abstract = {Motivation: RNA-binding proteins (RBPs) take over 5-10{\%} of the eukaryotic proteome and play key roles in many biological processes, e.g. gene regulation. Experimental detection of RBP binding sites is still time-intensive and high-costly. Instead, computational prediction of the RBP binding sites using patterns learned from existing annotation knowledge is a fast approach. From the biological point of view, the local structure context derived from local sequences will be recognized by specific RBPs. However, in computational modeling using deep learning, to our best knowledge, only global representations of entire RNA sequences are employed. So far, the local sequence information is ignored in the deep model construction process. Results: In this study, we present a computational method iDeepE to predict RNA-protein binding sites from RNA sequences by combining global and local convolutional neural networks (CNNs). For the global CNN, we pad the RNA sequences into the same length. For the local CNN, we split a RNA sequence into multiple overlapping fixed-length subsequences, where each subsequence is a signal channel of the whole sequence. Next, we train deep CNNs for multiple subsequences and the padded sequences to learn high-level features, respectively. Finally, the outputs from local and global CNNs are combined to improve the prediction. iDeepE demonstrates a better performance over state-of-the-art methods on two large-scale datasets derived from CLIP-seq. We also find that the local CNN runs 1.8 times faster than the global CNN with comparable performance when using GPUs. Our results show that iDeepE has captured experimentally verified binding motifs. Availability and implementation: https://github.com/xypan1232/iDeepE. Supplementary information: Supplementary data are available at Bioinformatics online.},
annote = {From Duplicate 1 (Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks - Pan, X; Shen, H B)

From Duplicate 1 (Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks - Pan, X; Shen, H B)
And Duplicate 3 (Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks - Pan, X; Shen, H B)

Pan, Xiaoyong
Shen, Hong-Bin
eng
England
Oxford, England
2018/05/04 06:00
Bioinformatics. 2018 Oct 15;34(20):3427-3436. doi: 10.1093/bioinformatics/bty364.

From Duplicate 2 (Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks - Pan, X; Shen, H B)

From Duplicate 1 (Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks - Pan, X; Shen, H B)
And Duplicate 2 (Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks - Pan, X; Shen, H B)

Pan, Xiaoyong
Shen, Hong-Bin
eng
England
Oxford, England
2018/05/04 06:00
Bioinformatics. 2018 Oct 15;34(20):3427-3436. doi: 10.1093/bioinformatics/bty364.},
author = {Pan, X and Shen, H B},
doi = {10.1093/bioinformatics/bty364},
file = {:E$\backslash$:/360yunpan/Mendeley/Predicting RNA–protein binding sites and motifs through combining local and global deep convolutional neural networks.pdf:pdf},
isbn = {1367-4811 (Electronic) 1367-4803 (Linking)},
journal = {Bioinformatics},
keywords = {ref29},
mendeley-tags = {ref29},
number = {20},
pages = {3427--3436},
pmid = {29722865},
title = {{Predicting RNA-protein binding sites and motifs through combining local and global deep convolutional neural networks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29722865},
volume = {34},
year = {2018}
}
@article{AlmagroArmenteros2017a,
abstract = {Motivation: The prediction of eukaryotic protein subcellular localization is a well-studied topic in bioinformatics due to its relevance in proteomics research. Many machine learning methods have been successfully applied in this task, but in most of them, predictions rely on annotation of homo-logues from knowledge databases. For novel proteins where no annotated homologues exist, and for predicting the effects of sequence variants, it is desirable to have methods for predicting protein properties from sequence information only. Results: Here, we present a prediction algorithm using deep neural networks to predict protein sub-cellular localization relying only on sequence information. At its core, the prediction model uses a recurrent neural network that processes the entire protein sequence and an attention mechanism identifying protein regions important for the subcellular localization. The model was trained and tested on a protein dataset extracted from one of the latest UniProt releases, in which experimen-tally annotated proteins follow more stringent criteria than previously. We demonstrate that our model achieves a good accuracy (78{\%} for 10 categories; 92{\%} for membrane-bound or soluble), out-performing current state-of-the-art algorithms, including those relying on homology information. Availability and implementation: The method is available as a web server at},
author = {{Almagro Armenteros}, Jos{\'{e}} Juan and S{\o}nderby, Casper Kaae and S{\o}nderby, S{\o}ren Kaae and Nielsen, Henrik and Winther, Ole},
doi = {10.1093/bioinformatics/btx431},
file = {:E$\backslash$:/360yunpan/Mendeley/DeepLocal predictioin of protein subcellular localization using deep learning.pdf:pdf},
issn = {13674811},
journal = {Bioinformatics (Oxford, England)},
title = {{DeepLoc: prediction of protein subcellular localization using deep learning}},
year = {2017}
}
@misc{Chu2018,
author = {Chu, Hong-Min and Yeh, Chih-Kuan and Wang, Yu-Chiang Frank},
booktitle = {The European Conference on Computer Vision},
chapter = {400-415},
title = {{Deep Generative Models for Weakly-Supervised Multi-Label Classification}},
year = {2018}
}
@article{BernadetteBouchon-MeunierRonaldR.Yager1995,
author = {{Bernadette Bouchon-Meunier, Ronald R. Yager}, Lotfi Asker Zadeh},
doi = {10.1007/978-3-319-52962-2},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep Learning Architectures for DNA Sequence Classification.pdf:pdf},
isbn = {9810223455},
keywords = {granular computing {\'{a}} information,granularity {\'{a}} coverage {\'{a}},granules {\'{a}} type and,information granules {\'{a}} principle,of justi fi able,order of,speci fi city},
number = {February},
pages = {497},
title = {{Fuzzy Logic and Soft Computing}},
volume = {3},
year = {1995}
}
@article{Khamis2018,
abstract = {Identifying transcription factor (TF) binding sites (TFBSs) is important in the computational inference of gene regulation. Widely used computational methods of TFBS prediction based on position weight matrices (PWMs) usually have high false positive rates. Moreover, computational studies of transcription regulation in eukaryotes frequently require numerous PWM models of TFBSs due to a large number of TFs involved. To overcome these problems we developed DRAF, a novel method for TFBS prediction that requires only 14 prediction models for 232 human TFs, while at the same time significantly improves prediction accuracy. DRAF models use more features than PWM models, as they combine information from TFBS sequences and physicochemical properties of TF DNA-binding domains into machine learning models. Evaluation of DRAF on 98 human ChIP-seq datasets shows on average 1.54-, 1.96- and 5.19-fold reduction of false positives at the same sensitivities compared to models from HOCOMOCO, TRANSFAC and DeepBind, respectively. This observation suggests that one can efficiently replace the PWM models for TFBS prediction by a small number of DRAF models that significantly improve prediction accuracy. The DRAF method is implemented in a web tool and in a stand-alone software freely available at http://cbrc.kaust.edu.sa/DRAF.},
author = {Khamis, Abdullah M. and Motwalli, Olaa and Oliva, Romina and Jankovic, Boris R. and Medvedeva, Yulia A. and Ashoor, Haitham and Essack, Magbubah and Gao, Xin and Bajic, Vladimir B.},
doi = {10.1093/nar/gky237},
file = {:E$\backslash$:/360yunpan/Mendeley/A novel method for improved accuracy of transcription factor binding site prediction.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Research},
number = {12},
publisher = {Oxford University Press},
title = {{A novel method for improved accuracy of transcription factor binding site prediction}},
volume = {46},
year = {2018}
}
@article{Pan2018d,
abstract = {Background: RNA regulation is significantly dependent on its binding protein partner, known as the RNA-binding proteins (RBPs). Unfortunately, the binding preferences for most RBPs are still not well characterized. Interdependencies between sequence and secondary structure specificities is challenging for both predicting RBP binding sites and accurate sequence and structure motifs detection. Results: In this study, we propose a deep learning-based method, iDeepS, to simultaneously identify the binding sequence and structure motifs from RNA sequences using convolutional neural networks (CNNs) and a bidirectional long short term memory network (BLSTM). We first perform one-hot encoding for both the sequence and predicted secondary structure, to enable subsequent convolution operations. To reveal the hidden binding knowledge from the observed sequences, the CNNs are applied to learn the abstract features. Considering the close relationship between sequence and predicted structures, we use the BLSTM to capture possible long range dependencies between binding sequence and structure motifs identified by the CNNs. Finally, the learned weighted representations are fed into a classification layer to predict the RBP binding sites. We evaluated iDeepS on verified RBP binding sites derived from large-scale representative CLIP-seq datasets. The results demonstrate that iDeepS can reliably predict the RBP binding sites on RNAs, and outperforms the state-of-the-art methods. An important advantage compared to other methods is that iDeepS can automatically extract both binding sequence and structure motifs, which will improve our understanding of the mechanisms of binding specificities of RBPs. Conclusion: Our study shows that the iDeepS method identifies the sequence and structure motifs to accurately predict RBP binding sites. iDeepS is available at https://github.com/xypan1232/iDeepS.},
annote = {From Duplicate 1 (Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks - Pan, Xiaoyong; Rijnbeek, Peter; Yan, Junchi; Shen, Hong-Bin B {\%}J Bin M C Genomics)

From Duplicate 2 (Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks - Pan, X; Rijnbeek, P; Yan, J; Shen, H B)

Pan, Xiaoyong
Rijnbeek, Peter
Yan, Junchi
Shen, Hong-Bin
eng
61671288/National Natural Science Foundation of China
61462018/National Natural Science Foundation of China
England
2018/07/05 06:00
BMC Genomics. 2018 Jul 3;19(1):511. doi: 10.1186/s12864-018-4889-1.

From Duplicate 2 (Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks - Pan, Xiaoyong; Rijnbeek, Peter; Yan, Junchi; Shen, Hong-Bin B {\%}J Bin M C Genomics)

From Duplicate 1 (Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks - Pan, X; Rijnbeek, P; Yan, J; Shen, H B)

Pan, Xiaoyong
Rijnbeek, Peter
Yan, Junchi
Shen, Hong-Bin
eng
61671288/National Natural Science Foundation of China
61462018/National Natural Science Foundation of China
England
2018/07/05 06:00
BMC Genomics. 2018 Jul 3;19(1):511. doi: 10.1186/s12864-018-4889-1.},
author = {Pan, Xiaoyong and Rijnbeek, Peter and Yan, Junchi and Shen, Hong-Bin B {\%}J Bin M C Genomics},
doi = {10.1186/s12864-018-4889-1},
file = {:E$\backslash$:/360yunpan/Mendeley/Prediction of RNA-protein sequence and structure binding preferences using deep convalutional and recurrent neural networks.pdf:pdf},
isbn = {1471-2164},
issn = {14712164},
journal = {BMC Genomics},
keywords = {*Neural Networks (Computer),Algorithms,Bidirectional long short term memory network,Binding Sites,Computational Biology/*methods,Convolutional neural network,Nucleic Acid Conformation,Nucleotide Motifs,Pan2018,Protein Binding,RNA-Binding Proteins/*metabolism,RNA-binding protein,RNA/*metabolism,Sequence motifs,Structure motifs,User-Computer Interface},
mendeley-tags = {Pan2018},
number = {1},
pages = {511},
pmid = {29970003},
publisher = {BMC Genomics},
title = {{Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks}},
url = {https://doi.org/10.1186/s12864-018-4889-1 http://www.ncbi.nlm.nih.gov/pubmed/29970003},
volume = {19},
year = {2018}
}
@article{Zhou2018a,
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
file = {:E$\backslash$:/360yunpan/Mendeley/Graph Neural Networks A Review of Methods and Applications.pdf:pdf},
pages = {1--22},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
url = {http://arxiv.org/abs/1812.08434},
year = {2018}
}
@article{Angermueller2016,
abstract = {Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.},
annote = {Angermueller, Christof
Parnamaa, Tanel
Parts, Leopold
Stegle, Oliver
eng
Wellcome Trust/United Kingdom
Review
Research Support, Non-U.S. Gov't
England
Mol Syst Biol. 2016 Jul 29;12(7):878. doi: 10.15252/msb.20156651.},
author = {Angermueller, C and Parnamaa, T and Parts, L and Stegle, O},
doi = {10.15252/msb.20156651},
edition = {2016/07/31},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep learning for computational biology.pdf:pdf},
isbn = {1744-4292 (Electronic) 1744-4292 (Linking)},
journal = {Mol Syst Biol},
keywords = {*cellular imaging,*computational biology,*deep learning,*machine learning,*regulatory genomics,Computational Biology/*methods,Genetic,Genomics/methods,Humans,Machine Learning,Models},
number = {7},
pages = {878},
pmid = {27474269},
title = {{Deep learning for computational biology}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/27474269},
volume = {12},
year = {2016}
}
@article{Chen2019,
abstract = {Accurate prediction of antigen presentation by human leukocyte antigen (HLA) class II molecules would be valuable for vaccine development and cancer immunotherapies. Current computational methods trained on in vitro binding data are limited by insufficient training data and algorithmic constraints. Here we describe MARIA (major histocompatibility complex analysis with recurrent integrated architecture; https://maria.stanford.edu/), a multimodal recurrent neural network for predicting the likelihood of antigen presentation from a gene of interest in the context of specific HLA class II alleles. In addition to in vitro binding measurements, MARIA is trained on peptide HLA ligand sequences identified by mass spectrometry, expression levels of antigen genes and protease cleavage signatures. Because it leverages these diverse training data and our improved machine learning framework, MARIA (area under the curve = 0.89–0.92) outperformed existing methods in validation datasets. Across independent cancer neoantigen studies, peptides with high MARIA scores are more likely to elicit strong CD4+ T cell responses. MARIA allows identification of immunogenic epitopes in diverse cancers and autoimmune disease.},
author = {Chen, Binbin and Khodadoust, Michael S. and Olsson, Niclas and Wagar, Lisa E. and Fast, Ethan and Liu, Chih Long and Muftuoglu, Yagmur and Sworder, Brian J. and Diehn, Maximilian and Levy, Ronald and Davis, Mark M. and Elias, Joshua E. and Altman, Russ B. and Alizadeh, Ash A.},
doi = {10.1038/s41587-019-0280-2},
file = {:E$\backslash$:/360yunpan/Mendeley/Predicting HLA class II antigen presentation through integrated deep learning.pdf:pdf},
isbn = {4158701902},
issn = {15461696},
journal = {Nature Biotechnology},
number = {11},
pages = {1332--1343},
pmid = {31611695},
publisher = {Springer US},
title = {{Predicting HLA class II antigen presentation through integrated deep learning}},
url = {http://dx.doi.org/10.1038/s41587-019-0280-2},
volume = {37},
year = {2019}
}
@article{Khamis2018,
abstract = {Identifying transcription factor (TF) binding sites (TFBSs) is important in the computational inference of gene regulation. Widely used computational methods of TFBS prediction based on position weight matrices (PWMs) usually have high false positive rates. Moreover, computational studies of transcription regulation in eukaryotes frequently require numerous PWM models of TFBSs due to a large number of TFs involved. To overcome these problems we developed DRAF, a novel method for TFBS prediction that requires only 14 prediction models for 232 human TFs, while at the same time significantly improves prediction accuracy. DRAF models use more features than PWM models, as they combine information from TFBS sequences and physicochemical properties of TF DNA-binding domains into machine learning models. Evaluation of DRAF on 98 human ChIP-seq datasets shows on average 1.54-, 1.96- and 5.19-fold reduction of false positives at the same sensitivities compared to models from HOCOMOCO, TRANSFAC and DeepBind, respectively. This observation suggests that one can efficiently replace the PWM models for TFBS prediction by a small number of DRAF models that significantly improve prediction accuracy. The DRAF method is implemented in a web tool and in a stand-alone software freely available at http://cbrc.kaust.edu.sa/DRAF.},
author = {Khamis, Abdullah M and Motwalli, Olaa and Oliva, Romina and Jankovic, Boris R and Medvedeva, Yulia A and Ashoor, Haitham and Essack, Magbubah and Gao, Xin and Bajic, Vladimir B},
doi = {10.1093/nar/gky237},
file = {:E$\backslash$:/360yunpan/Mendeley/A novel method for improved accuracy of transcription factor binding site prediction.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Research},
number = {12},
publisher = {Oxford University Press},
title = {{A novel method for improved accuracy of transcription factor binding site prediction}},
volume = {46},
year = {2018}
}
@article{Adhikari2019,
abstract = {Exciting new opportunities have arisen to solve the protein contact prediction problem from the progress in neural networks and the availability of a large number of homologous sequences through high-throughput sequencing. In this work, we study how deep convolutional neural network methods (ConvNets) may be best designed and developed to solve this long-standing problem. With publicly available datasets, we designed and trained various ConvNet architectures. We tested several recent deep learning techniques including wide residual networks, dropouts, and dilated convolutions. We studied the improvements in the precision of medium-range and long-range contacts, and compared the performance of our best architectures with the ones used in existing state-of-the-art methods. The proposed ConvNet architectures predict contacts with significantly more precision than the architectures used in several state-of-the-art methods. When trained using the DeepCov dataset consisting of 3,456 proteins and tested on PSICOV dataset of 150 proteins, our architectures achieve up to 15{\%} higher precision when L/2 long-range contacts are evaluated. Similarly, when trained using the DNCON2 dataset consisting of 1,426 proteins and tested on 84 protein domains in the CASP12 dataset, our single network achieves 4.8{\%} higher precision than the ensembled DNCON2 method when top L long-range contacts are evaluated. DEEPCON will be made publicly available at https://github.com/badriadhikari/DEEPCON/.},
author = {Adhikari, Badri},
doi = {10.1101/590455},
file = {:E$\backslash$:/360yunpan/Mendeley/DEEPCON Protein Contact Prediction using Dilated Convolutional Neural Networks with Dropout.pdf:pdf},
journal = {bioRxiv},
pages = {590455},
title = {{DEEPCON: Protein Contact Prediction using Dilated Convolutional Neural Networks with Dropout}},
url = {https://www.biorxiv.org/content/10.1101/590455v1?rss=1},
year = {2019}
}
@article{Papernot2018,
abstract = {Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.},
archivePrefix = {arXiv},
arxivId = {1803.04765},
author = {Papernot, Nicolas and McDaniel, Patrick},
eprint = {1803.04765},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep k-Nearest Neighbors.pdf:pdf},
number = {c},
title = {{Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning}},
url = {http://arxiv.org/abs/1803.04765},
year = {2018}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
author = {Vaswani, Ashish and Brain, Google and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
file = {:E$\backslash$:/360yunpan/Mendeley/attention is all you need.pdf:pdf},
journal = {Advances in neural information processing systems},
number = {Nips},
pages = {5998--6008},
title = {{Attention Is All You Need}},
url = {http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf},
year = {2017}
}
@article{Lee2016a,
abstract = {Understanding protein function from amino acid sequence is a fundamental prob-lem in biology. In this project, we explore how well we can represent biological function through examination of raw sequence alone. Using a large corpus of protein sequences and their annotated protein families, we learn dense vector rep-resentations for amino acid sequences using the co-occurrence statistics of short fragments. Then, using this representation, we experiment with several neural net-work architectures to train classifiers for protein family identification. We show good performance for a multi-class prediction problem with 589 protein family classes.},
author = {Lee, Timothy K and Nguyen, Tuan},
file = {:E$\backslash$:/360yunpan/Mendeley/Protein Family Classification with Neural Networks.pdf:pdf},
pages = {1--9},
title = {{Protein Family Classification with Neural Networks}},
year = {2016}
}
@article{Fang2018b,
abstract = {Protein secondary structure prediction can provide important information for protein 3D structure prediction and protein functions. Deep learning offers a new opportunity to significantly improve prediction accuracy. In this article, a new deep neural network architecture, named the Deep inception-inside-inception (Deep3I) network, is proposed for protein secondary structure prediction and implemented as a software tool MUFOLD-SS. The input to MUFOLD-SS is a carefully designed feature matrix corresponding to the primary amino acid sequence of a protein, which consists of a rich set of information derived from individual amino acid, as well as the context of the protein sequence. Specifically, the feature matrix is a composition of physio-chemical properties of amino acids, PSI-BLAST profile, and HHBlits profile. MUFOLD-SS is composed of a sequence of nested inception modules and maps the input matrix to either eight states or three states of secondary structures. The architecture of MUFOLD-SS enables effective processing of local and global interactions between amino acids in making accurate prediction. In extensive experiments on multiple datasets, MUFOLD-SS outperformed the best existing methods and other deep neural networks significantly. MUFold-SS can be downloaded from http://dslsrv8.cs.missouri.edu/{\~{}}cf797/MUFoldSS/download.html.},
annote = {Fang, Chao
Shang, Yi
Xu, Dong
eng
R01 GM100701/GM/NIGMS NIH HHS/
Research Support, U.S. Gov't, Non-P.H.S.
Research Support, N.I.H., Extramural
2018/03/02 06:00
Proteins. 2018 May;86(5):592-598. doi: 10.1002/prot.25487. Epub 2018 Mar 12.},
author = {Fang, C and Shang, Y and Xu, D},
doi = {10.1002/prot.25487},
file = {:E$\backslash$:/360yunpan/Mendeley/MUFOLD-SS New deep inception-inside-inception networks for protein secondary structure prediction.pdf:pdf},
isbn = {1097-0134 (Electronic) 0887-3585 (Linking)},
journal = {Proteins},
number = {5},
pages = {592--598},
pmid = {29492997},
title = {{MUFOLD-SS: New deep inception-inside-inception networks for protein secondary structure prediction}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29492997},
volume = {86},
year = {2018}
}
@article{Wang2019,
abstract = {Motivation: Computational methods for protein post-translational modification (PTM) site prediction provide a useful approach for studying protein functions. The prediction accuracy of the existing methods has significant room for improvement. A recent deep-learning architecture, Capsule Network (CapsNet), which can characterize the internal hierarchical representation of input data, presents a great opportunity to solve this problem, especially using small training data. Results: We proposed a CapsNet for predicting protein PTM sites, including phosphorylation, N-linked glycosylation, N6-acetyllysine, methyl-arginine, S-palmitoyl-cysteine, pyrrolidone-carboxylic-acid and SUMOylation sites. The CapsNet outperformed the baseline convolutional neural network architecture MusiteDeep and other well-known tools in most cases and provided promising results for practical use, especially in learning from small training data. The capsule length also gives an accurate estimate for the confidence of the PTM prediction. We further demonstrated that the internal capsule features could be trained as a motif detector of phosphorylation sites when no kinase-specific phosphorylation labels were provided. In addition, CapsNet generates robust representations that have strong discriminant power in distinguishing kinase substrates from different kinase families. Our study sheds some light on the recognition mechanism of PTMs and applications of CapsNet on other bioinformatic problems.},
author = {Wang, Duolin and Liang, Yanchun and Xu, Dong},
doi = {10.1093/bioinformatics/bty977},
file = {:E$\backslash$:/360yunpan/Mendeley/Capsule network for protein post-translational modification site prediction.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {14},
pages = {2386--2394},
title = {{Capsule network for protein post-translational modification site prediction}},
volume = {35},
year = {2019}
}
@article{Nielsen2018,
abstract = {Genetic engineering projects are rapidly growing in scale and complexity, driven by new tools to design and construct DNA. There is increasing concern that widened access to these technologies could lead to attempts to construct cells for malicious intent, illegal drug production, or to steal intellectual property. Determining the origin of a DNA sequence is difficult and time-consuming. Here deep learning is applied to predict the lab-of-origin of a DNA sequence. A convolutional neural network was trained on the Addgene plasmid dataset that contained 42,364 engineered DNA sequences from 2230 labs as of February 2016. The network correctly identifies the source lab 48{\%} of the time and 70{\%} it appears in the top 10 predicted labs. Often, there is not a single “smoking gun” that affiliates a DNA sequence with a lab. Rather, it is a combination of design choices that are individually common but collectively reveal the designer.},
author = {Nielsen, Alec A K and Voigt, Christopher A},
doi = {10.1038/s41467-018-05378-z},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep learning to predict the lab-of-origin of engineered DNA.pdf:pdf},
isbn = {4146701805},
issn = {20411723},
journal = {Nature Communications},
number = {1},
publisher = {Springer US},
title = {{Deep learning to predict the lab-of-origin of engineered DNA}},
url = {http://dx.doi.org/10.1038/s41467-018-05378-z},
volume = {9},
year = {2018}
}
@article{Liu2016f,
abstract = {Transcriptional enhancers are non-coding segments of DNA that play a central role in the spatiotemporal regulation of gene expression programs. However, systematically and precisely predicting enhancers remain a major challenge. Although existing methods have achieved some success in enhancer prediction, they still suffer from many issues. We developed a deep learning-based algorithmic framework named PEDLA (https://github.com/wenjiegroup/PEDLA), which can directly learn an enhancer predictor from massively heterogeneous data and generalize in ways that are mostly consistent across various cell types/tissues. We first trained PEDLA with 1,114-dimensional heterogeneous features in H1 cells, and demonstrated that PEDLA framework integrates diverse heterogeneous features and gives state-of-the-art performance relative to five existing methods for enhancer prediction. We further extended PEDLA to iteratively learn from 22 training cell types/tissues. Our results showed that PEDLA manifested superior performance consistency in both training and independent test sets. On average, PEDLA achieved 95.0{\%} accuracy and a 96.8{\%} geometric mean (GM) of sensitivity and specificity across 22 training cell types/tissues, as well as 95.7{\%} accuracy and a 96.8{\%} GM across 20 independent test cell types/tissues. Together, our work illustrates the power of harnessing state-of-the-art deep learning techniques to consistently identify regulatory elements at a genome-wide scale from massively heterogeneous data across diverse cell types/tissues.},
author = {Liu, Feng and Li, Hao and Ren, Chao and Bo, Xiaochen and Shu, Wenjie},
doi = {10.1038/srep28517},
file = {:E$\backslash$:/360yunpan/Mendeley/PEDLA predicting enhancers with deep learning-based algorithmic framework.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {June},
pages = {1--14},
publisher = {Nature Publishing Group},
title = {{PEDLA: Predicting enhancers with a deep learning-based algorithmic framework}},
url = {http://dx.doi.org/10.1038/srep28517},
volume = {6},
year = {2016}
}
@article{Khurana2018,
author = {Khurana, Sameer and Rawi, Reda and Kunji, Khalid and Chuang, Gwo-Yu and Bensmail, Halima and Mall, Raghvendra {\%}J Bioinformatics},
file = {:E$\backslash$:/360yunpan/Mendeley/DeepSol a deep learning framework for sequence-based protein solubility prediction.pdf:pdf},
pages = {2605--2613},
title = {{DeepSol: a deep learning framework for sequence-based protein solubility prediction}},
volume = {34 15},
year = {2018}
}
@misc{Li2018,
address = {Seoul, Republic of Korea},
author = {Li, Liang and Wang, Shuhui and Jiang, Shuqiang and Huang, Qingming},
booktitle = {Proceedings of the 26th ACM international conference on Multimedia},
doi = {10.1145/3240508.3240649},
pages = {1092--1100},
publisher = {ACM},
title = {{Attentive Recurrent Neural Network for Weak-supervised Multi-label Image Classification}},
year = {2018}
}
@article{Wen2018,
abstract = {Motivation: MicroRNAs (miRNAs) are small non-coding RNAs that function in RNA silencing and post-transcriptional regulation of gene expression by targeting messenger RNAs (mRNAs). Because the underlying mechanisms associated with miRNA binding to mRNA are not fully understood, a major challenge of miRNA studies involves the identification of miRNA-target sites on mRNA. In silico prediction of miRNA-target sites can expedite costly and time-consuming experimental work by providing the most promising miRNA-target-site candidates. Results: In this study, we reported the design and implementation of DeepMirTar, a deep-learning-based approach for accurately predicting human miRNA targets at the site level. The predicted miRNA-target sites are those having canonical or non-canonical seed, and features, including high-level expert-designed, low-level expert-designed and raw-data-level, were used to represent the miRNA-target site. Comparison with other state-of-the-art machine-learning methods and existing miRNA-target-prediction tools indicated that DeepMirTar improved overall predictive performance. Availability and implementation: DeepMirTar is freely available at https://github.com/Bjoux2/DeepMirTar{\_}SdA. Supplementary information: Supplementary data are available at Bioinformatics online.},
annote = {Wen, Ming
Cong, Peisheng
Zhang, Zhimin
Lu, Hongmei
Li, Tonghua
eng
England
Oxford, England
2018/06/06 06:00
Bioinformatics. 2018 Nov 15;34(22):3781-3787. doi: 10.1093/bioinformatics/bty424.},
author = {Wen, M and Cong, P and Zhang, Z and Lu, H and Li, T},
doi = {10.1093/bioinformatics/bty424},
file = {:E$\backslash$:/360yunpan/Mendeley/DeepMirTar a deep-learning approach for predicting human miRNA targets.pdf:pdf},
isbn = {1367-4811 (Electronic) 1367-4803 (Linking)},
journal = {Bioinformatics},
number = {22},
pages = {3781--3787},
pmid = {29868708},
title = {{DeepMirTar: a deep-learning approach for predicting human miRNA targets}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29868708 https://academic.oup.com/bioinformatics/article-abstract/34/22/3781/5026656?redirectedFrom=fulltext},
volume = {34},
year = {2018}
}
@article{Jiang,
author = {Jiang, Xue and Qian, Wei and Chen, Miao and Chen, Liang and Lin, Guan Ning},
file = {:E$\backslash$:/360yunpan/Mendeley/GAN-VAEMLP20190607.pdf:pdf},
pages = {1--17},
title = {{A generative adversarial network model for disease gene prediction with RNA-seq data Author summary}}
}
@article{Lee2013,
abstract = {We propose the simple and efficient method of semi-supervised learning for deep neural networks. Basically, the proposed network is trained in a supervised fashion with labeled and unlabeled data simultaneously. For un-labeled data, Pseudo-Labels, just picking up the class which has the maximum predicted probability, are used as if they were true labels. This is in effect equivalent to Entropy Regularization. It favors a low-density separation between classes, a commonly assumed prior for semi-supervised learning. With Denoising Auto-Encoder and Dropout, this simple method outperforms conventional methods for semi-supervised learning with very small labeled data on the MNIST handwritten digit dataset.},
author = {Lee, Dh},
doi = {10.1016/j.pediatrneurol.2013.08.008},
file = {:E$\backslash$:/360yunpan/Mendeley/Pseudo-Label the Simple and efficient semi-supervised learning method for deep neural networks.pdf:pdf},
issn = {1873-5150},
journal = {Proceedings of the International Conference on Machine Learning (ICML)},
number = {2},
pages = {1--4},
pmid = {24120650},
title = {{Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks}},
url = {https://kaggle2.blob.core.windows.net/forum-message-attachments/7371/pseudo{\_}label{\_}draft.pdf{\%}0Ahttp://deeplearning.net/wp-content/uploads/2013/03/pseudo{\_}label{\_}final.pdf},
volume = {1},
year = {2013}
}
@article{Zhu2017,
abstract = {Recently, pedestrian attributes like gender, age, clothing etc., have been used as soft biometric traits for recognizing people. Unlike existing methods that assume the independence of attributes during their prediction, we propose a multi-label convolutional neural network (MLCNN) to predict multiple attributes together in a unified framework. Firstly, a pedestrian image is roughly divided into multiple overlapping body parts, which are simultaneously integrated in the multi-label convolutional neural network. Secondly, these parts are filtered independently and aggregated in the cost layer. The cost function is a combination of multiple binary attribute classification cost functions. Experiments show that the proposed method significantly outperforms the SVM based method on the PETA database.},
author = {Zhu, Jianqing and Liao, Shengcai and Lei, Zhen and Li, Stan Z},
doi = {10.1016/j.imavis.2016.07.004},
file = {:E$\backslash$:/360yunpan/Mendeley/Multi-label convolutional neural network based pedestrian attribute classification.pdf:pdf},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Convolutional neural network,Multi-label classification,Pedestrian attribute classification},
pages = {224--229},
publisher = {Elsevier B.V.},
title = {{Multi-label convolutional neural network based pedestrian attribute classification}},
url = {http://dx.doi.org/10.1016/j.imavis.2016.07.004},
volume = {58},
year = {2017}
}
@article{Qu2019,
abstract = {This paper studies semi-supervised object classification in relational data, which is a fundamental problem in relational data modeling. The problem has been extensively studied in the literature of both statistical relational learning (e.g. relational Markov networks) and graph neural networks (e.g. graph convolutional networks). Statistical relational learning methods can effectively model the dependency of object labels through conditional random fields for collective classification, whereas graph neural networks learn effective object representations for classification through end-to-end training. In this paper, we propose the Graph Markov Neural Network (GMNN) that combines the advantages of both worlds. A GMNN models the joint distribution of object labels with a conditional random field, which can be effectively trained with the variational EM algorithm. In the E-step, one graph neural network learns effective object representations for approximating the posterior distributions of object labels. In the M-step, another graph neural network is used to model the local label dependency. Experiments on object classification, link classification, and unsupervised node representation learning show that GMNN achieves state-of-the-art results.},
archivePrefix = {arXiv},
arxivId = {1905.06214},
author = {Qu, Meng and Bengio, Yoshua and Tang, Jian},
eprint = {1905.06214},
file = {:E$\backslash$:/360yunpan/Mendeley/GMNN Graph Markov Neural Networks.pdf:pdf},
title = {{GMNN: Graph Markov Neural Networks}},
url = {http://arxiv.org/abs/1905.06214},
year = {2019}
}
@article{Fa2018,
abstract = {Machine learning methods for protein function prediction are urgently needed, especially now that a substantial fraction of known sequences remains unannotated despite the extensive use of functional assignments based on sequence similarity. One major bottleneck supervised learning faces in protein function prediction is the structured, multi-label nature of the problem, because biological roles are represented by lists of terms from hierarchically organised controlled vocabularies such as the Gene Ontology. In this work, we build on recent developments in the area of deep learning and investigate the usefulness of multi-task deep neural networks (MTDNN), which consist of upstream shared layers upon which are stacked in parallel as many independent modules (additional hidden layers with their own output units) as the number of output GO terms (the tasks). MTDNN learns individual tasks partially using shared representations and partially from task-specific characteristics. When no close homologues with experimentally validated functions can be identified, MTDNN gives more accurate predictions than baseline methods based on annotation frequencies in public databases or homology transfers. More importantly, the results show that MTDNN binary classification accuracy is higher than alternative machine learning-based methods that do not exploit commonalities and differences among prediction tasks. Interestingly, compared with a single-task predictor, the performance improvement is not linearly correlated with the number of tasks in MTDNN, but medium size models provide more improvement in our case. One of advantages of MTDNN is that given a set of features, there is no requirement for MTDNN to have a bootstrap feature selection procedure as what traditional machine learning algorithms do. Overall, the results indicate that the proposed MTDNN algorithm improves the performance of protein function prediction. On the other hand, there is still large room for deep learning techniques to further enhance prediction ability.},
author = {Fa, Rui and Cozzetto, Domenico and Wan, Cen and Jones, David T},
doi = {10.1371/journal.pone.0198216},
file = {:E$\backslash$:/360yunpan/Mendeley/Predicting human protein function with multitask deep neural networks.pdf:pdf},
journal = {PLoS ONE},
number = {6},
pages = {e0198216},
publisher = {Public Library of Science},
title = {{Predicting human protein function with multi-task deep neural networks}},
url = {https://doi.org/10.1371/journal.pone.0198216},
volume = {13},
year = {2018}
}
@article{Racle2019,
abstract = {Predictions of epitopes presented by class II human leukocyte antigen molecules (HLA-II) have limited accuracy, restricting vaccine and therapy design. Here we combined unbiased mass spectrometry with a motif deconvolution algorithm to profile and analyze a total of 99,265 unique peptides eluted from HLA-II molecules. We then trained an epitope prediction algorithm with these data and improved prediction of pathogen and tumor-associated class II neoepitopes.},
author = {Racle, Julien and Michaux, Justine and Rockinger, Georg Alexander and Arnaud, Marion and Bobisse, Sara and Chong, Chloe and Guillaume, Philippe and Coukos, George and Harari, Alexandre and Jandus, Camilla and Bassani-Sternberg, Michal and Gfeller, David},
doi = {10.1038/s41587-019-0289-6},
file = {:E$\backslash$:/360yunpan/Mendeley/Robust prediction of HLA class II epitopes by deep motif deconvolution of immunopeptidomes.pdf:pdf},
isbn = {4158701902},
issn = {15461696},
journal = {Nature Biotechnology},
number = {11},
pages = {1283--1286},
pmid = {31611696},
publisher = {Springer US},
title = {{Robust prediction of HLA class II epitopes by deep motif deconvolution of immunopeptidomes}},
url = {http://dx.doi.org/10.1038/s41587-019-0289-6},
volume = {37},
year = {2019}
}
@article{Wang2017d,
abstract = {Motivation: Computational methods for phosphorylation site prediction play important roles in protein function studies and experimental design. Most existing methods are based on feature extraction, which may result in incomplete or biased features. Deep learning as the cutting-edge machine learning method has the ability to automatically discover complex representations of phosphorylation patterns from the raw sequences, and hence it provides a powerful tool for improvement of phosphorylation site prediction. Results: We present MusiteDeep, the first deep-learning framework for predicting general and kinase-specific phosphorylation sites. MusiteDeep takes raw sequence data as input and uses convolutional neural networks with a novel two-dimensional attention mechanism. It achieves over a 50{\%} relative improvement in the area under the precision-recall curve in general phosphorylation site prediction and obtains competitive results in kinase-specific prediction compared to other well-known tools on the benchmark data. Availability and implementation: MusiteDeep is provided as an open-source tool available at https://github.com/duolinwang/MusiteDeep. Contact: xudong@missouri.edu. Supplementary information: Supplementary data are available at Bioinformatics online.},
annote = {Wang, Duolin
Zeng, Shuai
Xu, Chunhui
Qiu, Wangren
Liang, Yanchun
Joshi, Trupti
Xu, Dong
eng
R01 GM100701/GM/NIGMS NIH HHS/
England
Oxford, England
2017/10/17 06:00
Bioinformatics. 2017 Dec 15;33(24):3909-3916. doi: 10.1093/bioinformatics/btx496.},
author = {Wang, D and Zeng, S and Xu, C and Qiu, W and Liang, Y and Joshi, T and Xu, D},
doi = {10.1093/bioinformatics/btx496},
file = {:E$\backslash$:/360yunpan/Mendeley/MusiteDeep a deep learning framework for general and kinase-specific phosphorylation site prediction.pdf:pdf},
isbn = {1367-4811 (Electronic) 1367-4803 (Linking)},
journal = {Bioinformatics},
keywords = {*Machine Learning,*Software,Neural Networks (Computer),Phosphoproteins/*chemistry,Phosphorylation,Protein Kinases/metabolism,Protein/*methods,Proteins/metabolism,Sequence Analysis},
number = {24},
pages = {3909--3916},
pmid = {29036382},
title = {{MusiteDeep: a deep-learning framework for general and kinase-specific phosphorylation site prediction}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29036382},
volume = {33},
year = {2017}
}
@article{Racle2019a,
abstract = {Predictions of epitopes presented by class II human leukocyte antigen molecules (HLA-II) have limited accuracy, restricting vaccine and therapy design. Here we combined unbiased mass spectrometry with a motif deconvolution algorithm to profile and analyze a total of 99,265 unique peptides eluted from HLA-II molecules. We then trained an epitope prediction algorithm with these data and improved prediction of pathogen and tumor-associated class II neoepitopes.},
author = {Racle, Julien and Michaux, Justine and Rockinger, Georg Alexander and Arnaud, Marion and Bobisse, Sara and Chong, Chloe and Guillaume, Philippe and Coukos, George and Harari, Alexandre and Jandus, Camilla and Bassani-Sternberg, Michal and Gfeller, David},
doi = {10.1038/s41587-019-0289-6},
file = {:E$\backslash$:/360yunpan/Mendeley/Robust prediction of HLA class II epitopes by deep motif deconvolution of immunopeptidomes.pdf:pdf},
isbn = {4158701902},
issn = {15461696},
journal = {Nature Biotechnology},
number = {11},
pages = {1283--1286},
pmid = {31611696},
publisher = {Springer US},
title = {{Robust prediction of HLA class II epitopes by deep motif deconvolution of immunopeptidomes}},
url = {http://dx.doi.org/10.1038/s41587-019-0289-6},
volume = {37},
year = {2019}
}
@article{Xue2019,
abstract = {Motivation: Various bacterial pathogens can deliver their secreted substrates also called effectors through Type III secretion systems (T3SSs) into host cells and cause diseases. Since T3SS secreted effectors (T3SEs) play important roles in pathogen'host interactions, identifying them is crucial to our understanding of the pathogenic mechanisms of T3SSs. However, the effectors display high level of sequence diversity, therefore making the identification a difficult process. There is a need to develop a novel and effective method to screen and select putative novel effectors from bacterial genomes that can be validated by a smaller number of key experiments. Results: We develop a deep convolution neural network to directly classify any protein sequence into T3SEs or non-T3SEs, which is useful for both effector prediction and the study of sequence-function relationship. Different from traditional machine learning-based methods, our method automatically extracts T3SE-related features from a protein N-Terminal sequence of 100 residues and maps it to the T3SEs space. We train and test our method on the datasets curated from 16 species, yielding an average classification accuracy of 83.7{\%} in the 5-fold cross-validation and an accuracy of 92.6{\%} for the test set. Moreover, when comparing with known state-of-The-Art prediction methods, the accuracy of our method is 6.31-20.73{\%} higher than previous methods on a common independent dataset. Besides, we visualize the convolutional kernels and successfully identify the key features of T3SEs, which contain important signal information for secretion. Finally, some effectors reported in the literature are used to further demonstrate the application of DeepT3.},
author = {Xue, Li and Tang, Bin and Chen, Wei and Luo, Jiesi},
doi = {10.1093/bioinformatics/bty931},
file = {:E$\backslash$:/360yunpan/Mendeley/DeepT3 deep convolutional neural networks accurately identify Gram-negative bacterial type III secreted effectors using the N-terminal s.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
number = {12},
pages = {2051--2057},
title = {{DeepT3: Deep convolutional neural networks accurately identify Gram-negative bacterial type III secreted effectors using the N-Terminal sequence}},
volume = {35},
year = {2019}
}
@article{Zhou2018,
abstract = {{\textcopyright}2018 IEEE. Most of the traditional classification algorithms are based on the premise that the datasets are uniformly distributed or roughly equivalent. Once the sample dataset is not balanced , the classification performance drops sharply. To efficiently deal with the imbalance of data, an improved generative adversarial network (GAN) algorithm is proposed in this work. Firstly, we construct artificial samples so that more minority-class's data can be obtained via optimizing GAN loss function. Secondly, we build a fully-connected network for structured data classification. Finally, experimental evaluations are conducted on two open structured-datasets and the results of the proposed algorithm demonstrate a good applicability for the classification of structured data.},
author = {Zhou, Tingting and Liu, Wei and Zhou, Congyu and Chen, Leiting},
doi = {10.1109/INFOMAN.2018.8392662},
file = {:E$\backslash$:/360yunpan/Mendeley/GAN-based semi-supervised for imbalanced data classification.pdf:pdf},
isbn = {9781538661451},
journal = {2018 4th International Conference on Information Management, ICIM 2018},
keywords = {GAN,classification,component,imbalanced data,semi-supervised learning},
pages = {17--21},
publisher = {IEEE},
title = {{GAN-based semi-supervised for imbalanced data classification}},
year = {2018}
}
@article{Yu2016,
abstract = {As a new way of training generative models, Generative Adversarial Nets (GAN) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real-valued data. However, it has limitations when the goal is for generating sequences of discrete tokens. A major reason lies in that the discrete outputs from the generative model make it difficult to pass the gradient update from the discriminative model to the generative model. Also, the discriminative model can only assess a complete sequence, while for a partially generated sequence, it is non-trivial to balance its current score and the future one once the entire sequence has been generated. In this paper, we propose a sequence generation framework, called SeqGAN, to solve the problems. Modeling the data generator as a stochastic policy in reinforcement learning (RL), SeqGAN bypasses the generator differentiation problem by directly performing gradient policy update. The RL reward signal comes from the GAN discriminator judged on a complete sequence, and is passed back to the intermediate state-action steps using Monte Carlo search. Extensive experiments on synthetic data and real-world tasks demonstrate significant improvements over strong baselines.},
archivePrefix = {arXiv},
arxivId = {1609.05473},
author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
eprint = {1609.05473},
file = {:E$\backslash$:/360yunpan/Mendeley/SeqGAN Sequence Generative Adversarial Nets with Policy Gradient.pdf:pdf},
keywords = {Machine Learning Methods},
number = {Goodfellow},
pages = {2852--2858},
title = {{SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient}},
url = {http://arxiv.org/abs/1609.05473},
year = {2016}
}
@article{Jurtz2017,
abstract = {Motivation Deep neural network architectures such as convolutional and long short-term memory networks have become increasingly popular as machine learning tools during the recent years. The availability of greater computational resources, more data, new algorithms for training deep models and easy to use libraries for implementation and training of neural networks are the drivers of this development. The use of deep learning has been especially successful in image recognition; and the development of tools, applications and code examples are in most cases centered within this field rather than within biology. Results Here, we aim to further the development of deep learning methods within biology by providing application examples and ready to apply and adapt code templates. Given such examples, we illustrate how architectures consisting of convolutional and long short-term memory neural networks can relatively easily be designed and trained to state-of-the-art performance on three biological sequence problems: prediction of subcellular localization, protein secondary structure and the binding of peptides to MHC Class II molecules.},
author = {Jurtz, Vanessa Isabell and Johansen, Alexander Rosenberg and Nielsen, Morten and {Almagro Armenteros}, Jose Juan and Nielsen, Henrik and S{\o}nderby, Casper Kaae and Winther, Ole and S{\o}nderby, S{\o}ren Kaae},
doi = {10.1093/bioinformatics/btx531},
file = {:E$\backslash$:/360yunpan/Mendeley/An introduction to Deep learning on biological sequence data-examples and solutions.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
title = {{An introduction to deep learning on biological sequence data: Examples and solutions}},
year = {2017}
}
@article{Park2007,
abstract = {We introduce a path following algorithm for L1-regularized generalized linear mod- els.The L1-regularization procedure is useful especially because it, in effect, selects variables according to the amount of penalization on the L1-norm of the coefficients, in a manner that is less greedy than forward selection–backward deletion. The generalized linear model path algorithm efficiently computes solutions along the entire regularization path by using the pre- dictor–corrector method of convex optimization. Selecting the step length of the regularization parameter is critical in controlling the overall accuracy of the paths; we suggest intuitive and flexible strategies for choosing appropriate values. We demonstrate the implementation with several simulated and real data sets.},
archivePrefix = {arXiv},
arxivId = {1810.00826v3},
author = {Park, Mee Young and Hastie, Trevor},
doi = {10.1111/j.1467-9868.2007.00607.x},
eprint = {1810.00826v3},
file = {:E$\backslash$:/360yunpan/Mendeley/How Powerful Are Graph Neural Networks.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Generalized linear model,Lasso,Path algorithm,Predictor-corrector method,Regularization,Variable selection},
number = {4},
pages = {659--677},
title = {{How powerful are Graph Networks?}},
volume = {69},
year = {2007}
}
@article{Tarvainen2017,
abstract = {The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35{\%} on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55{\%} to 6.28{\%}, and on ImageNet 2012 with 10{\%} of the labels from 35.24{\%} to 9.11{\%}.},
archivePrefix = {arXiv},
arxivId = {1703.01780},
author = {Tarvainen, Antti and Valpola, Harri},
eprint = {1703.01780},
file = {:E$\backslash$:/360yunpan/Mendeley/Mean teachers are better role models weight-averaged consistency targets improve semi-supervised deep learning results.pdf:pdf},
title = {{Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results}},
url = {http://arxiv.org/abs/1703.01780},
year = {2017}
}
@article{Yue2019,
abstract = {Graph embedding learning which aims to automatically learn low-dimensional node representations has drawn increasing attention in recent years. To date, most recent graph embedding methods are mainly evaluated on social and information networks and have not been comprehensively studied on biomedical networks under systematic experiments and analyses. On the other hand, for a variety of biomedical network analysis tasks, traditional techniques such as matrix factorization have shown promising results, and hence there is a need to systematically evaluate the more recent graph embedding methods (e.g., random walk-based and neural network-based) in terms of their usability and potential to further the state-of-the-art. We select 11 representative graph embedding methods and conduct a systematic comparison on three important biomedical link prediction tasks: drug-disease association prediction, drug-drug interaction prediction, protein-protein interaction prediction, and two node classification tasks: medical term semantic type classification, protein function prediction. Our experimental results demonstrate that the recent graph embedding methods which have not been explored completely on biomedical tasks achieve promising results and deserve more attention in the future biomedical graph analysis. Besides, compared with three state-of-the-art methods for DDAs, DDIs and protein function predictions, the recent graph embedding methods achieve competitive performance without using any biological features. By summarizing the experimental results, we provide general guidelines for properly selecting graph embedding methods and setting their hyper-parameters for different biomedical tasks. We also develop an easy-to-use Python package with detailed instructions, BioNEV, including all source code and datasets, to facilitate studying various graph embedding methods on biomedical tasks.},
archivePrefix = {arXiv},
arxivId = {1906.05017},
author = {Yue, Xiang and Wang, Zhen and Huang, Jingong and Parthasarathy, Srinivasan and Moosavinasab, Soheil and Huang, Yungui and Lin, Simon M and Zhang, Wen and Zhang, Ping and Sun, Huan},
doi = {10.1093/bioinformatics/btz718},
eprint = {1906.05017},
file = {:E$\backslash$:/360yunpan/Mendeley/Graph Embedding on Biomedical Networks- Methods Applications and Evalutions.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
title = {{Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations}},
year = {2019}
}
@article{Zhou2015b,
abstract = {Identifying functional effects of noncoding variants is a major challenge in human genetics. To predict the noncoding-variant effects de novo from sequence, we developed a deep learning-based algorithmic framework, DeepSEA (http://deepsea.princeton.edu/), that directly learns a regulatory sequence code from large-scale chromatin-profiling data, enabling prediction of chromatin effects of sequence alterations with single-nucleotide sensitivity. We further used this capability to improve prioritization of functional variants including expression quantitative trait loci (eQTLs) and disease-associated variants.},
author = {Zhou, Jian and Troyanskaya, Olga G {\%}J Nat Methods},
doi = {10.1038/nmeth.3547},
file = {:E$\backslash$:/360yunpan/Mendeley/Predicting effects of noncoding variants with deep learning–based sequence model.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {Zhou2015},
mendeley-tags = {Zhou2015},
title = {{Predicting effects of noncoding variants with deep learning-based sequence model}},
url = {https://doi.org/10.1038/nmeth.3547},
volume = {12},
year = {2015}
}
@article{Tutubalina2017,
abstract = {Adverse drug reactions (ADRs) are an essential part of the analysis of drug use, measuring drug use benefits, and making policy decisions. Traditional channels for identifying ADRs are reliable but very slow and only produce a small amount of data. Text reviews, either on specialized web sites or in general-purpose social networks, may lead to a data source of unprecedented size, but identifying ADRs in free-form text is a challenging natural language processing problem. In this work, we propose a novel model for this problem, uniting recurrent neural architectures and conditional random fields. We evaluate our model with a comprehensive experimental study, showing improvements over state-of-the-art methods of ADR extraction.},
author = {Tutubalina, Elena and Nikolenko, Sergey},
doi = {10.1155/2017/9451342},
file = {:E$\backslash$:/360yunpan/Mendeley/Combination of Deep Recurrent Neural Networks and Conditional Random Fields for Extracting Adverse Drug Reactions from User Reviews.pdf:pdf},
issn = {20402309},
journal = {Journal of Healthcare Engineering},
title = {{Combination of Deep Recurrent Neural Networks and Conditional Random Fields for Extracting Adverse Drug Reactions from User Reviews}},
volume = {2017},
year = {2017}
}
@article{Wang2018d,
abstract = {The complex system of gene expression is regulated by the cell type-specific binding of transcription factors (TFs) to regulatory elements. Identifying variants that disrupt TF binding and lead to human diseases remains a great challenge. To address this, we implement sequence-based deep learning models that accurately predict the TF binding intensities to given DNA sequences. In addition to accurately classifying TF-DNA binding or unbinding, our models are capable of accurately predicting real-valued TF binding intensities by leveraging large-scale TF ChIP-seq data. The changes in the TF binding intensities between the altered sequence and the reference sequence reflect the degree of functional impact for the variant. This enables us to develop the tool DeFine (Deep learning based Functional impact of non-coding variants evaluator, http://define.cbi.pku.edu.cn) with improved performance for assessing the functional impact of non-coding variants including SNPs and indels. DeFine accurately identifies the causal functional non-coding variants from disease-associated variants in GWAS. DeFine is an effective and easy-to-use tool that facilities systematic prioritization of functional non-coding variants.},
annote = {Wang, Meng
Tai, Cheng
E, Weinan
Wei, Liping
eng
England
2018/04/05 06:00
Nucleic Acids Res. 2018 Jun 20;46(11):e69. doi: 10.1093/nar/gky215.},
author = {Wang, M and Tai, C and E, W and Wei, L},
doi = {10.1093/nar/gky215},
file = {:E$\backslash$:/360yunpan/Mendeley/DeFine--deep convolutional neural networks accurately quantify intensities of transcription.pdf:pdf},
isbn = {1362-4962 (Electronic) 0305-1048 (Linking)},
journal = {Nucleic Acids Res},
number = {11},
pages = {e69},
pmid = {29617928},
title = {{DeFine: deep convolutional neural networks accurately quantify intensities of transcription factor-DNA binding and facilitate evaluation of functional non-coding variants}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29617928},
volume = {46},
year = {2018}
}
@article{Gandhi2018,
abstract = {Motivation Determining RNA binding protein(RBP) binding specificity is crucial for understanding many cellular processes and genetic disorders. RBP binding is known to be affected by both the sequence and structure of RNAs. Deep learning can be used to learn generalizable representations of raw data and has improved state of the art in several fields such as image classification, speech recognition and even genomics. Previous work on RBP binding has either used shallow models that combine sequence and structure or deep models that use only the sequence. Here we combine both abilities by augmenting and refining the original Deepbind architecture to capture structural information and obtain significantly better performance.

Results We propose two deep architectures, one a lightweight convolutional network for transcriptome wide inference and another a Long Short-Term Memory(LSTM) network that is suitable for small batches of data. We incorporate computationally predicted secondary structure features as input to our models and show its effectiveness in boosting prediction performance. Our models achieved significantly higher correlations on held out in-vitro test data compared to previous approaches, and generalise well to in-vivo CLIP-SEQ data achieving higher median AUCs than other approaches. We analysed the output from our model for VTS1 and CPO and provided intuition into its working. Our models confirmed known secondary structure preferences for some proteins as well as found new ones where secondary structure might play a role. We also demonstrated the strengths of our model compared to other approaches such as the ability to combine information from long distances along the input.

Availability Software and models are available at {\textless}https://github.com/shreshthgandhi/cDeepbind{\textgreater}

Contact ljlee{\{}at{\}}psi.toronto.edu, frey{\{}at{\}}psi.toronto.edu},
author = {Gandhi, Shreshth and Lee, Leo J. and Delong, Andrew and Duvenaud, David and Frey, Brendan J.},
doi = {10.1101/345140},
file = {:E$\backslash$:/360yunpan/Mendeley/cDeepbind A context sensitive deep learning model of RNA-protein binding.pdf:pdf},
journal = {bioRxiv},
pages = {345140},
title = {{cDeepbind: A context sensitive deep learning model of RNA-protein binding}},
url = {https://www.biorxiv.org/content/10.1101/345140v1},
year = {2018}
}
@article{Yang2017,
abstract = {Motivation Enhancer elements are noncoding stretches of DNA that play key roles in controlling gene expression programmes. Despite major efforts to develop accurate enhancer prediction methods, identifying enhancer sequences continues to be a challenge in the annotation of mammalian genomes. One of the major issues is the lack of large, sufficiently comprehensive and experimentally validated enhancers for humans or other species. Thus, the development of computational methods based on limited experimentally validated enhancers and deciphering the transcriptional regulatory code encoded in the enhancer sequences is urgent. Results We present a deep-learning-based hybrid architecture, BiRen, which predicts enhancers using the DNA sequence alone. Our results demonstrate that BiRen can learn common enhancer patterns directly from the DNA sequence and exhibits superior accuracy, robustness and generalizability in enhancer prediction relative to other state-of-the-art enhancer predictors based on sequence characteristics. Our BiRen will enable researchers to acquire a deeper understanding of the regulatory code of enhancer sequences. Availability and Implementation Our BiRen method can be freely accessed at https://github.com/wenjiegroup/BiRen . Contact shuwj@bmi.ac.cn or boxc@bmi.ac.cn. Supplementary information Supplementary data are available at Bioinformatics online.},
author = {Yang, Bite and Liu, Feng and Ren, Chao and Ouyang, Zhangyi and Xie, Ziwei and Bo, Xiaochen and Shu, Wenjie},
doi = {10.1093/bioinformatics/btx105},
file = {:E$\backslash$:/360yunpan/Mendeley/BiRen predicting enhancers with a deep-learning-based model using the DNA sequence alone.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
title = {{BiRen: Predicting enhancers with a deep-learning-based model using the DNA sequence alone}},
year = {2017}
}
@book{Elbasir2018,
abstract = {Motivation: Protein structure determination has primarily been performed using X-ray crystallography. To overcome the expensive cost, high attrition rate and series of trial-and-error settings, many in-silico methods have been developed to predict crystallization propensities of proteins based on their sequences. However, the majority of these methods build their predictors by extracting features from protein sequences, which is computationally expensive and can explode the feature space. We propose DeepCrystal, a deep learning framework for sequence-based protein crystallization prediction. It uses deep learning to identify proteins which can produce diffraction quality crystals without the need to manually engineer additional biochemical and structural features from sequence. Our model is based on Convolutional Neural Networks (CNNs), which can exploit frequently occurring k-mers and sets of k-mers from the protein sequences to distinguish proteins that will result in diffraction quality crystals from those that will not. Results: Our model surpasses previous sequence-based protein crystallization predictors in terms of recall, F-score, accuracy and MCC on three independent test sets. DeepCrystal achieves an average improvement of 1.4{\%}, 12.1{\%} in recall, when compared to its closest competitors, Crysalis II and Crysf respectively. In addition, DeepCrystal attains an average improvement of 2.1{\%}, 6.0{\%} for F-score, 1.9{\%}, 3.9{\%} for accuracy and 3.8{\%}, 7.0{\%} for MCC w.r.t. Crysalis II and Crysf on independent test sets. Availability: The standalone source code and models are available at https://github.com/elbasir/DeepCrystal and a web-server is also available at https://deeplearning-protein.qcri.org.},
author = {Elbasir, Abdurrahman and Moovarkumudalvan, Balasubramanian and Kolatkar, Prasanna and Kunji, Khalid and Bensmail, Halima and Mall, Raghvendra},
doi = {10.1093/bioinformatics/bty953},
file = {:E$\backslash$:/360yunpan/Mendeley/DeepCrystal A Deep Learning Framework for Sequence-based Protein Crystallization Prediction.pdf:pdf},
title = {{DeepCrystal: A Deep Learning Framework for Sequence-based Protein Crystallization Prediction}},
url = {https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty953/5194339?redirectedFrom=fulltext},
year = {2018}
}
@inproceedings{LoBosco2017,
abstract = {DNA sequence classification is a key task in a generic computational framework for biomedical data analysis, and in recent years several machine learning technique have been adopted to successful accomplish with this task. Anyway, the main difficulty behind the problem remains the feature selection process. Sequences do not have explicit features, and the commonly used representations introduce the main drawback of the high dimensionality. For sure, machine learning method devoted to supervised classification tasks are strongly dependent on the feature extraction step, and in order to build a good representation it is necessary to recognize and measure meaningful details of the items to classify. Recently, neural deep learning architectures or deep learning models, were proved to be able to extract automatically useful features from input patterns. In this work we present two different deep learning architectures for the purpose of DNA sequence classification. Their comparison is carried out on a public data-set of DNA sequences, for five different classification tasks. {\textcopyright} Springer International Publishing AG 2017.},
author = {{Lo Bosco}, Giosu{\'{e}} and {Di Gangi}, Mattia Antonino},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-52962-2_14},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep Learning Architectures for DNA Sequence Classification.pdf:pdf},
issn = {16113349},
keywords = {Convolutional neural networks,DNA sequence classification,Deep learning networks,Recurrent neural networks},
title = {{Deep learning architectures for DNA sequence classification}},
year = {2017}
}
@article{Chen2019a,
author = {Chen, Lei and Pan, Xiaoyong and Zhang, Yu-hang and Liu, Min and Huang, Tao and Cai, Yu-dong},
doi = {10.1016/j.csbj.2018.12.002},
issn = {2001-0370},
journal = {Computational and Structural Biotechnology Journal},
keywords = {Enrichment theory,Incremental feature selection,Minimum redundancy maximum relevance,Rarely expressed gene,Recurrent neural network,Widely expressed gene,rarely expressed gene,widely expressed gene},
pages = {49--60},
publisher = {The Authors},
title = {{Classification of Widely and Rarely Expressed Genes with Recurrent Neural Network}},
url = {https://doi.org/10.1016/j.csbj.2018.12.002},
volume = {17},
year = {2019}
}
@article{Tang2019a,
abstract = {Extracting inherent valuable knowledge from omics big data remains as a daunting problem in bioinformatics and computational biology. Deep learning, as an emerging branch from machine learning, has exhibited unprecedented performance in quite a few applications from academia and industry. We highlight the difference and similarity in widely utilized models in deep learning studies, through discussing their basic structures, and reviewing diverse applications and disadvantages. We anticipate the work can serve as a meaningful perspective for further development of its theory, algorithm and application in bioinformatic and computational biology.},
annote = {Tang, Binhua
Pan, Zixiang
Yin, Kang
Khateeb, Asif
eng
Review
Switzerland
Front Genet. 2019 Mar 26;10:214. doi: 10.3389/fgene.2019.00214. eCollection 2019.},
author = {Tang, B and Pan, Z and Yin, K and Khateeb, A},
doi = {10.3389/fgene.2019.00214},
file = {:E$\backslash$:/360yunpan/Mendeley/Tang-2019-Recent Advances of Deep Learning in.pdf:pdf},
isbn = {1664-8021 (Print) 1664-8021 (Linking)},
journal = {Front Genet},
keywords = {algorithm,application,bioinformatics,computational biology,deep learning},
pages = {214},
pmid = {30972100},
title = {{Recent Advances of Deep Learning in Bioinformatics and Computational Biology}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/30972100 https://fjfsdata01prod.blob.core.windows.net/articles/files/420104/pubmed-zip/.versions/1/.package-entries/fgene-10-00214/fgene-10-00214.pdf?sv=2015-12-11{\&}sr=b{\&}sig=rdKcfELsz2RFnmbgKnVfPDAjeqTCA{\%}2BAu{\%}2B4nNSzAFgH},
volume = {10},
year = {2019}
}
@book{Liu2017a,
abstract = {As high-throughput biological sequencing becomes faster and cheaper, the need to extract useful information from sequencing becomes ever more paramount, often limited by low-throughput experimental characterizations. For proteins, accurate prediction of their functions directly from their primary amino-acid sequences has been a long standing challenge. Here, machine learning using artificial recurrent neural networks (RNN) was applied towards classification of protein function directly from primary sequence without sequence alignment, heuristic scoring or feature engineering. The RNN models containing long-short-term-memory (LSTM) units trained on public, annotated datasets from UniProt achieved high performance for in-class prediction of four important protein functions tested, particularly compared to other machine learning algorithms using sequence-derived protein features. RNN models were used also for out-of-class predictions of phylogenetically distinct protein families with similar functions, including proteins of the CRISPR-associated nuclease, ferritin-like iron storage and cytochrome P450 families. Applying the trained RNN models on the partially unannotated UniRef100 database predicted not only candidates validated by existing annotations but also currently unannotated sequences. Some RNN predictions for the ferritin-like iron sequestering function were experimentally validated, even though their sequences differ significantly from known, characterized proteins and from each other and cannot be easily predicted using popular bioinformatics methods. As sequencing and experimental characterization data increases rapidly, the machine-learning approach based on RNN could be useful for discovery and prediction of homologues for a wide range of protein functions.},
author = {Liu, Xueliang},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep Recurrent Neural Network for Protein Function Prediction from Sequence.pdf:pdf},
title = {{Deep Recurrent Neural Network for Protein Function Prediction from Sequence}},
year = {2017}
}
@article{Angermueller2017,
abstract = {Recent technological advances have enabled assaying DNA methylation in single cells. Current protocols are limited by incomplete CpG coverage and hence methods to predict missing methylation states are critical to enable genome-wide analyses. We here report DeepCpG, a computational approach based on deep neural networks to predict DNA methylation states from DNA sequence and incomplete methylation profiles in single cells. We validate DeepCpG on mouse embryonic stem cells, where we report substantially more accurate predictions than previous methods. Additionally, we show that DeepCpG provides new insights for interpreting the sources of epigenetic diversity. Our model can be used to estimate the effect of single nucleotide changes and we uncover sequence motifs that are associated with DNA methylation level and epigenetic heterogeneity.},
author = {Angermueller, Christof and Lee, Heather J and Reik, Wolf and Stegle, Oliver},
doi = {10.1186/s13059-017-1189-z},
file = {:E$\backslash$:/360yunpan/Mendeley/DeepCpG Accurate prediction of single-cell DNA methylation states using deep learning.pdf:pdf},
isbn = {1305901711},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Artificial neural network,DNA methylation,Deep learning,Epigenetics,Machine learning,Single-cell genomics},
number = {1},
pages = {1--13},
publisher = {Genome Biology},
title = {{DeepCpG: Accurate prediction of single-cell DNA methylation states using deep learning}},
volume = {18},
year = {2017}
}
@article{Kumar2017b,
author = {Kumar, Aviral and Ramakrishnan, Ganesh},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep Learning Approaches to the Multi-Instance Multi-Label Learning Problem.pdf:pdf},
journal = {Department of computer science and engineering},
number = {Miml},
publisher = {Indian Institute of Technology Bombay},
title = {{Deep Learning Approaches to the Multi-Instance Multi-Label ( MIML ) Learning Problem}},
year = {2017}
}
@article{Gao2017,
abstract = {Convolutional Neural Networks (ConvNets) have achieved excellent recognition performance in various visual recognition tasks. A large labeled training set is one of the most important factors for its success. However, it is difficult to collect sufficient training images with precise labels in some domains such as apparent age estimation, head pose estimation, multi-label classification and semantic segmentation. Fortunately, there is ambiguous information among labels, which makes these tasks different from traditional classification. Based on this observation, we convert the label of each image into a discrete label distribution, and learn the label distribution by minimizing a Kullback-Leibler divergence between the predicted and ground-truth label distributions using deep ConvNets. The proposed DLDL (Deep Label Distribution Learning) method effectively utilizes the label ambiguity in both feature learning and classifier learning, which help prevent the network from over-fitting even when the training set is small. Experimental results show that the proposed approach produces significantly better results than state-of-the-art methods for age estimation and head pose estimation. At the same time, it also improves recognition performance for multi-label classification and semantic segmentation tasks.},
author = {Gao, Bin-Bin and Xing, Chao and Xie, Chen-Wei and Wu, Jianxin and Geng, Xin},
doi = {10.1109/TIP.2017.2689998},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep label distribution learning with label ambiguity.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
keywords = {Label distribution,age estimation,deep learning,head pose estimation,semantic segmentation},
number = {6},
pages = {2825--2838},
title = {{Deep Label Distribution Learning With Label Ambiguity}},
url = {http://ieeexplore.ieee.org/document/7890384/},
volume = {26},
year = {2017}
}
@article{Wu2019,
abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes and benchmarks of the existing algorithms on different learning tasks. Finally, we propose potential research directions in this rapidly growing field.},
archivePrefix = {arXiv},
arxivId = {1901.00596},
author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
eprint = {1901.00596},
file = {:E$\backslash$:/360yunpan/Mendeley/A Comprehensive Survey on Graph Neural Networks.pdf:pdf},
number = {Xx},
pages = {1--22},
title = {{A Comprehensive Survey on Graph Neural Networks}},
url = {http://arxiv.org/abs/1901.00596},
volume = {XX},
year = {2019}
}
@book{Perdana2018,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Perdana},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:E$\backslash$:/360yunpan/Mendeley/Deep{\_}Learning{\_}with{\_}Keras.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Deep learning with Keras}},
volume = {53},
year = {2018}
}
